#!/usr/bin/env python3
"""
==================================================================================
FASE 2: ANÃ€LISI DE CORRELACIÃ“ I SELECCIÃ“ DE CARACTERÃSTIQUES
IdentificaciÃ³ de les 9 variables mÃ©s predictives per a penicilÂ·lina
==================================================================================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy.stats import spearmanr
from statsmodels.stats.outliers_influence import variance_inflation_factor
import warnings
warnings.filterwarnings('ignore')

PROJECT_ROOT = Path(__file__).parent.parent.parent
OUTPUT_DIR = PROJECT_ROOT / "fases" / "2_exploracio_preparacio" / "outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("=" * 80)
print("FASE 2: ANÃ€LISI DE CORRELACIÃ“ I SELECCIÃ“ DE CARACTERÃSTIQUES")
print("=" * 80)

# Carregar dataset processat
print("\n[1/4] Carregant dataset processat...")
data_file = OUTPUT_DIR / "03_penicillin_dataset_33_columns.csv"

if not data_file.exists():
    print(f"âŒ ERROR: Primer has d'executar 03_data_cleaning_and_feature_engineering.py")
    exit(1)

df = pd.read_csv(data_file)
print(f"âœ… Dataset carregat: {len(df):,} files Ã— {len(df.columns)} columnes")

# Eliminar columnes no numÃ¨riques
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
if 'batch_id' in numeric_cols:
    numeric_cols.remove('batch_id')

df_numeric = df[numeric_cols].copy()
print(f"   Variables numÃ¨riques: {len(numeric_cols)}")

# =============================================================================
# ANÃ€LISI DE CORRELACIÃ“
# =============================================================================
print("\n[2/4] Calculant correlacions amb penicilÂ·lina...")

if 'penicillin' not in df_numeric.columns:
    print("âŒ ERROR: La columna 'penicillin' no existeix al dataset")
    exit(1)

# CorrelaciÃ³ de Pearson
corr_pearson = df_numeric.corr()['penicillin'].sort_values(ascending=False)

# CorrelaciÃ³ de Spearman
corr_spearman = {}
for col in df_numeric.columns:
    if col != 'penicillin':
        corr, _ = spearmanr(df_numeric[col], df_numeric['penicillin'], nan_policy='omit')
        corr_spearman[col] = corr

corr_spearman = pd.Series(corr_spearman).sort_values(ascending=False)

# Crear DataFrame comparatiu
df_correlations = pd.DataFrame({
    'Variable': corr_pearson.index,
    'Pearson': corr_pearson.values,
    'Spearman': [corr_spearman.get(var, 0) for var in corr_pearson.index],
    'Abs_Pearson': np.abs(corr_pearson.values)
})

df_correlations = df_correlations[df_correlations['Variable'] != 'penicillin']
df_correlations = df_correlations.sort_values('Abs_Pearson', ascending=False)

print(f"\nðŸ“Š Top 15 variables mÃ©s correlacionades:")
for idx, row in df_correlations.head(15).iterrows():
    print(f"   {row['Variable']:30s}: Pearson={row['Pearson']:+.3f}, Spearman={row['Spearman']:+.3f}")

# Guardar correlacions
corr_file = OUTPUT_DIR / "04_correlations_with_penicillin.csv"
df_correlations.to_csv(corr_file, index=False)
print(f"\nâœ… Correlacions guardades: {corr_file.name}")

# VisualitzaciÃ³ de correlacions
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))

# GrÃ fic 1: Top 15 Pearson
top_15 = df_correlations.head(15)
colors = ['green' if x > 0 else 'red' for x in top_15['Pearson']]

ax1.barh(range(len(top_15)), top_15['Pearson'], color=colors, alpha=0.7, edgecolor='black')
ax1.set_yticks(range(len(top_15)))
ax1.set_yticklabels(top_15['Variable'])
ax1.set_xlabel('CorrelaciÃ³ de Pearson', fontsize=13)
ax1.set_title('Top 15 Variables Correlacionades amb PenicilÂ·lina (Pearson)', 
              fontsize=14, fontweight='bold')
ax1.axvline(x=0, color='black', linestyle='-', linewidth=0.8)
ax1.grid(True, alpha=0.3, axis='x')

# GrÃ fic 2: Pearson vs Spearman
ax2.scatter(top_15['Pearson'], top_15['Spearman'], s=150, alpha=0.6, 
           c=range(len(top_15)), cmap='viridis', edgecolors='black', linewidths=2)

for i, var in enumerate(top_15['Variable']):
    ax2.annotate(var, (top_15.iloc[i]['Pearson'], top_15.iloc[i]['Spearman']),
                fontsize=9, ha='right', alpha=0.7)

ax2.plot([-1, 1], [-1, 1], 'k--', alpha=0.3, linewidth=2)
ax2.set_xlabel('CorrelaciÃ³ de Pearson', fontsize=13)
ax2.set_ylabel('CorrelaciÃ³ de Spearman', fontsize=13)
ax2.set_title('ComparaciÃ³ Pearson vs Spearman', fontsize=14, fontweight='bold')
ax2.grid(True, alpha=0.3)
ax2.set_xlim(-1, 1)
ax2.set_ylim(-1, 1)

plt.tight_layout()
corr_plot = OUTPUT_DIR / "04_correlation_analysis.png"
plt.savefig(corr_plot, dpi=300, bbox_inches='tight')
plt.close()
print(f"âœ… GrÃ fic de correlacions guardat: {corr_plot.name}")

# =============================================================================
# SELECCIÃ“ DE TOP 9 CARACTERÃSTIQUES
# =============================================================================
print("\n[3/4] Seleccionant les 9 variables mÃ©s predictives...")

# Algorisme greedy per minimitzar multicolinealitat (VIF)
selected_features = []
remaining_candidates = df_correlations.head(20)['Variable'].tolist()

print("\n   SelecciÃ³ iterativa (minimitzant VIF):")

for i in range(min(9, len(remaining_candidates))):
    best_feature = None
    min_max_vif = float('inf')
    
    for candidate in remaining_candidates:
        test_features = selected_features + [candidate]
        
        # Calcular VIF per aquesta combinaciÃ³
        X_test = df_numeric[test_features].dropna()
        
        if len(X_test) > len(test_features) and X_test.shape[1] > 1:
            try:
                vif_values = []
                for j in range(X_test.shape[1]):
                    vif = variance_inflation_factor(X_test.values, j)
                    vif_values.append(vif)
                
                max_vif = max(vif_values)
                
                if max_vif < min_max_vif:
                    min_max_vif = max_vif
                    best_feature = candidate
            except:
                # Si falla el cÃ lcul de VIF, seleccionar per correlaciÃ³
                if best_feature is None:
                    best_feature = candidate
    
    if best_feature:
        selected_features.append(best_feature)
        remaining_candidates.remove(best_feature)
        corr_val = df_correlations[df_correlations['Variable'] == best_feature]['Pearson'].values[0]
        print(f"      {i+1}. {best_feature:30s} (r={corr_val:+.3f}, VIF_max={min_max_vif:.2f})")

print(f"\nâœ… {len(selected_features)} variables seleccionades!")

# Crear dataset reduÃ¯t
df_reduced = df[selected_features + ['penicillin', 'batch_id', 'time']].copy()
reduced_file = OUTPUT_DIR / "04_penicillin_dataset_top9_features.csv"
df_reduced.to_csv(reduced_file, index=False)
print(f"   ðŸ’¾ Dataset reduÃ¯t guardat: {reduced_file.name}")

# =============================================================================
# MATRIU DE CORRELACIÃ“
# =============================================================================
print("\n[4/4] Generant matriu de correlaciÃ³...")

# Matriu per les 9 variables seleccionades
corr_matrix = df_numeric[selected_features + ['penicillin']].corr()

plt.figure(figsize=(12, 10))

mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', 
            center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8},
            vmin=-1, vmax=1)

plt.title('Matriu de CorrelaciÃ³ - Top 9 Variables + PenicilÂ·lina', 
          fontsize=16, fontweight='bold', pad=20)
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(rotation=0, fontsize=10)
plt.tight_layout()

matrix_plot = OUTPUT_DIR / "04_correlation_matrix_top9.png"
plt.savefig(matrix_plot, dpi=300, bbox_inches='tight')
plt.close()
print(f"âœ… Matriu de correlaciÃ³ guardada: {matrix_plot.name}")

# Guardar resum final
summary_file = OUTPUT_DIR / "04_selected_features_summary.txt"
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("RESUM DE SELECCIÃ“ DE CARACTERÃSTIQUES\n")
    f.write("=" * 80 + "\n\n")
    
    f.write("ðŸŽ¯ 9 VARIABLES SELECCIONADES PER PREDICCIÃ“ DE PENICILÂ·LINA:\n\n")
    
    for i, feat in enumerate(selected_features, 1):
        corr = df_correlations[df_correlations['Variable'] == feat]['Pearson'].values[0]
        f.write(f"   {i}. {feat:30s} (r = {corr:+.3f})\n")
    
    f.write("\n" + "=" * 80 + "\n")
    f.write("\nðŸ“Š JUSTIFICACIÃ“ TEÃ’RICA:\n\n")
    
    justifications = {
        'biomass': 'Directament relacionada amb producciÃ³ (q_P Â· X)',
        'time': 'Fase del procÃ©s (producciÃ³ en fase estacionÃ ria)',
        'substrate': 'Control de limitaciÃ³ per substrat',
        'DO': 'Metabolisme aerÃ²bic essencial',
        'pH': 'Afecta activitat enzimÃ tica de biosÃ­ntesi',
        'temperature': 'Afecta cinÃ¨tica enzimÃ tica',
        'volume': 'EstratÃ¨gia fed-batch i diluciÃ³',
        'specific_production_rate': 'Velocitat especÃ­fica de biosÃ­ntesi',
        'cumulative_penicillin': 'ProducciÃ³ acumulada total',
        'yield_PX': 'EficiÃ¨ncia de conversiÃ³ biomassa-producte',
        'OUR': 'Indicador d\'activitat metabÃ²lica',
        'CER': 'Indicador d\'activitat metabÃ²lica',
        'RQ': 'Estat metabÃ²lic del microorganisme'
    }
    
    for feat in selected_features:
        if feat in justifications:
            f.write(f"   â€¢ {feat}: {justifications[feat]}\n")
    
    f.write("\n" + "=" * 80 + "\n")

print(f"âœ… Resum guardat: {summary_file.name}")

print("\n" + "=" * 80)
print("âœ… ANÃ€LISI DE CORRELACIÃ“ I SELECCIÃ“ COMPLETADA")
print("=" * 80)
print(f"\nðŸ“ Fitxers generats:")
print(f"   â€¢ {corr_file.name}")
print(f"   â€¢ {corr_plot.name}")
print(f"   â€¢ {reduced_file.name}")
print(f"   â€¢ {matrix_plot.name}")
print(f"   â€¢ {summary_file.name}")
print(f"\nðŸ“‚ Tots els fitxers a: {OUTPUT_DIR}")
print(f"\nðŸŽ‰ FASE 2 COMPLETADA!")
print("=" * 80 + "\n")
